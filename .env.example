# ======================
# Graphiti + Ollama MCP 服務器環境配置範本
# ======================

# ======================
# Neo4j 圖資料庫配置
# ======================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=YOUR_PASSWORD

# ======================
# Ollama 本地 LLM 配置
# ======================
# 覆蓋 OpenAI 設定，使用 Ollama
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434/v1

# 推薦的 LLM 模型（按效能/效果平衡排序）
# 1. qwen2.5:7b - 最佳平衡，快速且效果好 (推薦)
# 2. qwen2.5:14b - 最佳效果，但較慢
# 3. llama3.2:3b-instruct-fp16 - 最快但效果較差
MODEL_NAME=qwen2.5:7b
SMALL_MODEL_NAME=qwen2.5:7b

# 嵌入模型（必須安裝）
# 支援的模型：nomic-embed-text:v1.5, all-minilm:l6-v2
EMBEDDER_MODEL_NAME=nomic-embed-text:v1.5

# ======================
# Graphiti 系統配置
# ======================
# 記憶分組 ID（用於多租戶隔離）
GROUP_ID=default

# 並發限制（本地 LLM 建議較低值避免過載）
SEMAPHORE_LIMIT=3

# 關閉遙測（隱私保護）
GRAPHITI_TELEMETRY_ENABLED=false

# ======================
# 進階配置（可選）
# ======================
# Ollama 服務器地址
OLLAMA_BASE_URL=http://localhost:11434

# LLM 溫度設定（0.0-1.0，值越低越穩定）
LLM_TEMPERATURE=0.1

# ======================
# 除錯配置（開發時使用）
# ======================
# 啟用除錯日誌
# DEBUG=false

# 日誌級別
# LOG_LEVEL=INFO